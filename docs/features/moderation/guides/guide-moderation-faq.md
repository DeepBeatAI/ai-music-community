# Moderation FAQ

## Frequently Asked Questions About Moderation

This document answers common questions about the moderation system, reporting content, and community guidelines on the AI Music Community Platform.

## General Questions

### What is moderation?

Moderation is the process of reviewing content and user behavior to ensure compliance with our [Community Guidelines](guide-community-guidelines.md). Our moderation team reviews reports, takes action on violations, and helps maintain a safe and respectful community.

### Who are the moderators?

Moderators are trusted community members and platform staff who have been granted special permissions to review reports and take action on guideline violations. They undergo training and follow established procedures to ensure fair and consistent enforcement.

### How do I become a moderator?

Moderator positions are typically offered to:
- Active, trusted community members
- Users with a history of positive contributions
- Individuals who demonstrate good judgment and fairness

We announce moderator applications when positions are available. Check platform announcements for opportunities.

## Reporting Content

### How do I report content?

1. Click the **report button (ðŸš©)** on the content
2. Select the violation category
3. Provide additional details if needed
4. Submit your report

For detailed instructions, see the [User Reporting Guide](guide-user-reporting.md).

### What types of content can I report?

You can report:
- Posts
- Comments
- Tracks (audio content)
- User profiles

### What categories can I choose when reporting?

- Spam or Misleading Content
- Harassment or Bullying
- Hate Speech
- Inappropriate Content
- Copyright Violation
- Impersonation
- Self-Harm or Dangerous Acts
- Other (requires description)

### How many reports can I submit?

You can submit up to **10 reports per 24 hours**. This limit prevents abuse while allowing legitimate reporting.

### What happens if I exceed the report limit?

If you try to submit more than 10 reports in 24 hours, you'll see an error message and won't be able to submit additional reports until the time period expires.

### Can I report the same content multiple times?

No, submitting multiple reports for the same content doesn't speed up the review process. Submit one clear, detailed report per violation.

### Will the person I report know it was me?

No, your identity as a reporter is kept confidential. Only moderators and admins can see who submitted a report, and this information is used for accountability purposes only.

## After Reporting

### How long does it take for a report to be reviewed?

Review times depend on:
- **Priority level**: P1 (critical) reports are reviewed first
- **Queue volume**: The number of pending reports
- **Moderator availability**: Active moderator hours

Typical review times:
- **P1 (Critical)**: Within hours
- **P2 (High)**: Within 24 hours
- **P3 (Standard)**: Within 2-3 days
- **P4-P5 (Low)**: Within a week

### How is priority determined?

Priority is automatically assigned based on the violation category:
- **P1 (Critical)**: Self-harm or dangerous acts
- **P2 (High)**: Hate speech, harassment
- **P3 (Standard)**: Spam, inappropriate content, copyright
- **P4-P5 (Low)**: Other violations

### Will I be notified of the outcome?

Currently, reporters are not automatically notified of outcomes. However, you can:
- Check if the reported content has been removed
- See if the user's account status has changed

Future updates may include reporter notifications.

### What if my report is dismissed?

If your report is dismissed:
- The moderator determined the content doesn't violate guidelines
- The content remains on the platform
- Your report is logged for record-keeping
- You can still report other violations

This doesn't mean your report was wrongâ€”interpretation of guidelines can vary, and context matters.

### Can I appeal a dismissed report?

There's currently no formal appeal process for dismissed reports. However:
- If you believe a serious violation was missed, you can submit a new report with more context
- Repeated reports of the same content may be flagged as abuse

## Moderation Actions

### What actions can moderators take?

Moderators can:
- Remove or hide content
- Issue warnings to users
- Apply restrictions (disable posting, commenting, or uploading)
- Suspend accounts temporarily (1, 7, or 30 days)
- Dismiss reports if no violation occurred

Admins can also permanently ban users for severe violations.

### What happens when content is removed?

When content is removed:
- The content is permanently deleted from the platform
- The content owner receives a notification explaining why
- The report is marked as "resolved"
- The action is logged in the moderation system

### What's the difference between suspension and restriction?

**Suspension:**
- Temporarily blocks all account activity
- Durations: 1, 7, or 30 days
- User cannot post, comment, upload, or interact
- Account is restored automatically when suspension expires

**Restriction:**
- Blocks specific activities only
- Types: Posting disabled, commenting disabled, or uploading disabled
- Can be temporary or permanent
- User can still use other platform features

### Can I appeal a moderation action?

Yes, if you believe a moderation action was taken in error:
1. Review the notification explaining the action
2. Check the [Community Guidelines](guide-community-guidelines.md)
3. Contact support through the help center
4. Provide context for why you believe the action was incorrect

**Note:** The formal appeal process is currently being developed.

### How long do suspensions last?

Temporary suspensions last:
- **1 day**: Minor violations or first-time offenses
- **7 days**: Moderate violations or repeated offenses
- **30 days**: Severe violations or multiple repeated offenses

Permanent bans are reserved for critical violations or users who repeatedly violate guidelines.

### Do violations expire from my record?

Moderation actions are logged indefinitely for accountability. However:
- Minor violations may not affect future moderation decisions
- Demonstrating improved behavior can influence future outcomes
- Severe violations remain on record permanently

## Content Guidelines

### What content is not allowed?

See the [Community Guidelines](guide-community-guidelines.md) for a complete list. Key prohibited content includes:
- Spam and misleading content
- Harassment and bullying
- Hate speech
- Inappropriate content
- Copyright violations
- Impersonation
- Self-harm promotion

### Can I post AI-generated music?

Yes! AI-generated music is welcome on the platform. However, you **must**:
- Clearly disclose that the content is AI-generated
- Specify the AI tool used
- Provide accurate metadata
- Respect copyright of training data

### What about controversial or edgy content?

Controversial content is allowed as long as it doesn't violate guidelines. However:
- Avoid content that promotes hatred or violence
- Be respectful in discussions
- Consider your audience
- Expect diverse reactions

### Can I criticize other users' work?

Yes, constructive criticism is encouraged. However:
- Be respectful and helpful
- Focus on the work, not the person
- Avoid personal attacks
- Provide specific, actionable feedback

### What if I'm unsure if content violates guidelines?

When in doubt:
- Review the [Community Guidelines](guide-community-guidelines.md)
- Consider the intent and context
- Ask yourself if it's respectful and safe
- Contact support for guidance
- Err on the side of caution

## Account Issues

### What if I'm being harassed?

If you're experiencing harassment:
1. **Report the content** immediately using the report button
2. **Block the user** to prevent further contact
3. **Document the harassment** (screenshots if needed)
4. **Contact support** for urgent situations
5. **Don't engage** with the harasser

### Can I create a new account if I'm banned?

No, creating new accounts to evade bans is prohibited and may result in:
- Immediate ban of the new account
- Extension of the original ban
- Permanent ban from the platform

### What if my account was hacked?

If your account is compromised:
1. **Change your password** immediately
2. **Review recent activity** for unauthorized actions
3. **Contact support** to report the compromise
4. **Report any unauthorized content** posted from your account

We may reverse moderation actions if we verify your account was compromised.

### How do I protect my account?

- Use a strong, unique password
- Enable two-factor authentication (when available)
- Don't share your credentials
- Log out on shared devices
- Be cautious of phishing attempts

## Reporting System

### What if I accidentally report something?

Accidental reports happen. Don't worry:
- Moderators review all reports carefully
- Context and intent are considered
- False reports don't automatically result in action
- Your report history is considered

However, repeatedly reporting content that doesn't violate guidelines may be flagged as abuse.

### Can I report someone for disagreeing with me?

No, disagreements and differences of opinion are not violations. Only report content that actually violates [Community Guidelines](guide-community-guidelines.md).

### What if someone is abusing the report system?

If you believe someone is abusing the reporting system:
- Contact support with evidence
- Don't retaliate by reporting their content
- Let moderators handle the situation

Abuse of the reporting system is taken seriously and may result in restrictions.

### Can I see who reported my content?

No, reporter identities are confidential. This protects users from retaliation and encourages honest reporting.

## Moderator Actions

### Can moderators see my private messages?

Moderators can only see:
- Public content (posts, comments, tracks)
- Reported content and context
- User profiles and public information

Private messages are not accessible to moderators unless specifically reported.

### What if I disagree with a moderator's decision?

If you disagree with a moderation decision:
1. Review the reason provided in your notification
2. Check the [Community Guidelines](guide-community-guidelines.md)
3. Contact support to discuss the decision
4. Provide additional context if relevant

Moderators are human and can make mistakes. We review appeals carefully.

### Are moderators paid?

Moderator compensation varies:
- Some moderators are platform staff (paid)
- Some are volunteer community moderators
- All moderators follow the same guidelines and procedures

### Can moderators be reported?

Yes, if you believe a moderator is:
- Abusing their powers
- Acting unfairly or with bias
- Violating guidelines themselves

Contact support with specific details and evidence.

## Technical Questions

### Why can't I post/comment/upload?

If you're unable to perform these actions:
- Check your notifications for restriction notices
- You may have an active restriction or suspension
- Contact support if you believe this is an error

### How do I know if I'm restricted?

You'll receive a notification explaining:
- The type of restriction
- The reason for the restriction
- The duration (if temporary)
- How to appeal (when available)

### When will my restriction expire?

Check your notification for the expiration date. Restrictions expire automatically:
- Time-based restrictions end on the specified date
- Permanent restrictions require appeal or admin review

### What if I think there's a bug in the moderation system?

If you encounter technical issues:
- Document the problem with screenshots
- Note the exact steps to reproduce
- Contact support with details
- Report through the bug reporting system (if available)

## Community Standards

### Who decides what violates guidelines?

Guidelines are:
- Established by platform administrators
- Based on legal requirements and community values
- Enforced by trained moderators
- Updated periodically based on feedback

### Can guidelines change?

Yes, guidelines may be updated to:
- Address new types of violations
- Clarify existing rules
- Respond to community feedback
- Comply with legal requirements

Significant changes are announced to the community.

### How can I provide feedback on guidelines?

We welcome feedback:
- Contact support with suggestions
- Participate in community discussions
- Respond to feedback requests
- Share your perspective respectfully

## Getting Help

### Where can I get more information?

- [User Reporting Guide](guide-user-reporting.md) - Detailed reporting instructions
- [Community Guidelines](guide-community-guidelines.md) - Complete rules and standards
- [User Safety Guide](guide-user-safety.md) - Safety tips and best practices
- Help Center - Platform support resources

### How do I contact support?

- Visit the Help Center on the platform
- Use the contact form in your account settings
- Email: support@aimusiccommunity.com (example)

### What if my question isn't answered here?

If you have additional questions:
- Check the Help Center for more resources
- Contact support for personalized assistance
- Review other documentation guides
- Ask in community forums (when available)

---

## Still Have Questions?

We're here to help! Contact support through the platform's help center or review our other documentation:

- [User Reporting Guide](guide-user-reporting.md)
- [Community Guidelines](guide-community-guidelines.md)
- [User Safety Guide](guide-user-safety.md)
- [Moderator Training Guide](guide-moderator-training.md) (for moderators)

---

*Last Updated: December 2025*  
*This FAQ is updated regularly based on common questions and community feedback.*
